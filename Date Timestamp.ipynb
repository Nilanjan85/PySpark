{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f8b5c1e-1198-465c-a322-c7d9d668bcc1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import * \n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1890dda-9ab9-4f00-9121-9eda92676149",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------------+\n| id|     today|                 now|\n+---+----------+--------------------+\n|  0|2023-07-29|2023-07-29 15:57:...|\n+---+----------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "date_df = spark.range(1).withColumn('today',current_date()) \\\n",
    "            .withColumn('now',current_timestamp())\n",
    "date_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a093577-158d-440f-a665-d2856a42f5a0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+\n|     today|date_add(today, 5)|date_sub(today, 5)|\n+----------+------------------+------------------+\n|2023-07-23|        2023-07-28|        2023-07-18|\n+----------+------------------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "#Adding and sub date from current date\n",
    "date_df.select(col('today'),date_add(col('today'),5), date_sub(col('today'),5)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19944764-2f5e-4787-ab02-fe207641a15e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n|datediff(today, week ago)|\n+-------------------------+\n|                        7|\n+-------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# difference between dates in days and months\n",
    "\n",
    "date_df.withColumn('week ago', date_sub(col('today'),7)) \\\n",
    "    .select(datediff(col('today'),col('week ago'))) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b8dd437-42e4-4e54-9231-7734a98e84c8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---------------+\n|Start date|  End date| diff in months|\n+----------+----------+---------------+\n|2023-01-04|2023-07-25|           -7.0|\n+----------+----------+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "date_df.select(to_date(lit('2023-01-04')).alias(\"Start date\"), \\\n",
    "        to_date(lit('2023-07-25')).alias(\"End date\"), \\\n",
    "        round(months_between(col(\"Start date\"),col(\"End date\"))).alias(\" diff in months\")\n",
    "               ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d436b8a-91f6-4618-ae39-e6c7887b1bcd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+\n|wrong date format|Date correct format|\n+-----------------+-------------------+\n|             null|         2023-07-23|\n+-----------------+-------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# If the date format is wrong in databrciks it will be treated as NULL. \n",
    "date_df.select(to_date(lit('2023-22-05')).alias(\"wrong date format\"), to_date(col('today')).alias(\"Date correct format\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41fa3698-a4bb-44da-af58-ad34066de1d3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n|wrong date format|\n+-----------------+\n|       2023-04-05|\n+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "# date should be 4 th May but displaying as 5 th April.\n",
    "date_df.select(to_date(lit('2023-04-05')).alias(\"wrong date format\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e83b1b7-bbf1-406b-b68c-8ed473ef897e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+\n|right date |    Risht timestamp|\n+-----------+-------------------+\n| 2023-05-04|2023-05-04 00:00:00|\n+-----------+-------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Solution to the above problem. \n",
    "dateFormat = 'yyyy-dd-MM'\n",
    "date_df.select(to_date(lit('2023-04-05'),dateFormat).alias(\"right date \"), \\\n",
    "               to_timestamp(lit('2023-04-05'),dateFormat).alias(\"Risht timestamp\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c465521-09a8-4caf-8213-aa3b665860c0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n|Diff date format|\n+----------------+\n|      2023-07-29|\n+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "# To convert a string to date we have to use to_date function. Here the first arg is the date string and 2 nd arg is the format in which the date is specified in the date string. The output will be a date in the default date format eg. yyyy-MM-dd\n",
    "date_df.select(to_date(lit('29-07-2023'),'dd-MM-yyyy').alias(\"Diff date format\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30bade9a-ae68-4c98-b2f8-09abf1a78ce7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n|Date Formated|\n+-------------+\n|   29/07/2023|\n+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Convert a date to string by using date_format function. \n",
    "date_df.select(date_format(to_date(lit('29-07-2023'),'dd-MM-yyyy'),'dd/MM/yyyy').alias(\"Date Formated\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a445d3d-600f-48b5-b49a-56e7edfa4154",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n|Date Formated|\n+-------------+\n|          210|\n+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "date_df.select(date_format(to_date(lit('29-07-2023'),'dd-MM-yyyy'),'yyyyMMdd').alias(\"Date Formated\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7af033b-388f-465d-9e0c-c62596d3d949",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n|day-of-year|\n+-----------+\n|        210|\n+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "date_df.select(date_format(to_date(lit('29-07-2023'),'dd-MM-yyyy'),'D').alias(\"day-of-year\")).show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Date Timestamp",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
